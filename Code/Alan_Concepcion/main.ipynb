{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from factor_analyzer import calculate_bartlett_sphericity, calculate_kmo, FactorAnalyzer\n",
    "import spotipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konrad -- Make sure .env variables have the same name\n",
    "load_dotenv()\n",
    "SPOTIFY_KEY1 = os.getenv('SPOTIFY_KEY1')\n",
    "SPOTIFY_KEY2 = os.getenv('SPOTIFY_KEY2')\n",
    "SPOTIFY_DATA = os.getenv('SPOTIFY_DATA')\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(SPOTIFY_KEY1,SPOTIFY_KEY2))\n",
    "df_spotify = pd.read_csv(SPOTIFY_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape\")\n",
    "df_spotify.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = df_spotify.duplicated().sum()\n",
    "print(\"Dupe rows:\")\n",
    "dupes\n",
    "df_spotify.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null values:\")\n",
    "df_spotify.isnull().any()\n",
    "df_spotify.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I determine which columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_columns = df_spotify.drop(columns=['id','name','release_date','artists','year', 'explicit', 'popularity'\n",
    "                                               ,'mode','key','liveness','duration_ms'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing spotify api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(track):\n",
    "    print('\\nArtist: ' + track['artists'][0]['name'])\n",
    "    print('Track: ' + track['name'])\n",
    "    print('Album: ' + track['album']['name'])\n",
    "    AP = track['preview_url']\n",
    "    if AP is None:\n",
    "        print(\"No Audio Preview available\")\n",
    "    else:\n",
    "        print('Audio Preview: ' + track['preview_url'])\n",
    "    print('Cover Art: ' + track['album']['images'][0]['url'])\n",
    "\n",
    "# Testing spotify api, works so far\n",
    "    found = False\n",
    "    while not found:\n",
    "        track_id = input(\"Enter uri: \")\n",
    "        if spotify.track(track_id):\n",
    "            found = True\n",
    "\n",
    "track = spotify.track(track_id)\n",
    "print_info(track)\n",
    "song_features = spotify.audio_features(track_id)\n",
    "songDF = pd.DataFrame(song_features)\n",
    "print(songDF)\n",
    "songDF = songDF.drop(columns=['track_href','analysis_url','type','id','uri','time_signature'\n",
    "                                  ,'mode','key','liveness','duration_ms'])\n",
    "print(songDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have the dataset loaded and input song time to start Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Factor Analysis\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(df_relevant_columns)\n",
    "print(chi_square_value, p_value)\n",
    "kmo_all,kmo_model=calculate_kmo(df_relevant_columns)\n",
    "print(kmo_model) # this number should be higher than 0.60 and as close to 1.0 as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Individual kmo values:\")\n",
    "print(kmo_all) # If any of the values are less than 0.50, they could be dropped depending on how much value they have to the model, liveness was below 0.50 after consideration it was dropped above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer()\n",
    "fa.fit(df_relevant_columns, 25)\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "print(ev) # look at the matrix here, how many values above 1.0, in this case its 2 so for n_factors at fa.set_params(n_factors=2, rotation=\"varimax\"), using 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2 numbers in this case were above 1.0 so n_factors will be set to 2 later but lets graph and get further clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(1,df_relevant_columns.shape[1]+1),ev) # extra verification with this graph\n",
    "plt.plot(range(1,df_relevant_columns.shape[1]+1),ev) # notice that after 2 we don't get significant changes and it just sorta repeats\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant changes after X=2 so again n_factors will be set to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.set_params(n_factors=2, rotation=\"varimax\") # using 2 here for n_factors from above\n",
    "fa.fit(df_relevant_columns)\n",
    "factor_loading_matrix = pd.DataFrame(fa.loadings_, columns=['Factor 1', 'Factor 2'],index=df_relevant_columns.columns.tolist())\n",
    "print(factor_loading_matrix) # for further details please read the datacamp link on what these values signify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_get_factor_matrix = pd.DataFrame(fa.get_factor_variance(), columns=['Factor 1', 'Factor 2'],index=['SS Loadings', 'Proportion Var', 'Cumulative Var'])\n",
    "print(factor_get_factor_matrix) # for further details please read the datacamp link on what these values signify but tldr look at the last \n",
    "                                # Cumulative Var number in this case it's 0.477090 or 47% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_columns.dropna(inplace=True)\n",
    "scaler = StandardScaler() # tested other scalers\n",
    "X = scaler.fit_transform(df_relevant_columns)\n",
    "k = NearestNeighbors(n_neighbors=7, metric='euclidean', algorithm='ball_tree') # can set different params\n",
    "k.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for the input song\n",
    "input_song_details = songDF[df_relevant_columns.columns]\n",
    "input_song_aesthetic = scaler.transform(input_song_details)\n",
    "print(input_song_details) # Sanity check\n",
    "print(input_song_aesthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caler.fit_transform(df_relevant_columns)\n",
    "distance, indices = k.kneighbors(input_song_aesthetic)\n",
    "recommended_songs = df.iloc[indices.flatten()][['artists', 'name','id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # having issues with same songs showing up i.e Artist: Taylor Swift Track: I Knew You Were Trouble, showing up 3 times since there is like 5 versions, here is a hack fix\n",
    "# only issue is if song that is inputted is NOT in dataset wont have dupes and it just ends up ommiting a song\n",
    "recommended_songs = recommended_songs.drop_duplicates()\n",
    "print(recommended_songs.head(6)[1:])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
